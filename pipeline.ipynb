{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:08:47.711348Z",
     "iopub.status.busy": "2024-07-06T22:08:47.710070Z",
     "iopub.status.idle": "2024-07-06T22:08:47.725186Z",
     "shell.execute_reply": "2024-07-06T22:08:47.724018Z",
     "shell.execute_reply.started": "2024-07-06T22:08:47.711306Z"
    },
    "id": "kdgAJlPoh4d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = './images'\n",
    "MODEL_PATH = './resnet18_letters.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJJ_07ATlYfm"
   },
   "source": [
    "Вам предстоит создать алгоритм по деформации (выравниваню) автомобильных номеров и поместить его в функцию img_deformation.\n",
    "\n",
    "\n",
    "! Вы не можете менять заданную OCR модель (дообучать тоже нельзя) и заданные шаблоны по разбиению изображения.\n",
    "\n",
    "! Допустимы небольшие измениния трех основных .py файлов, если в этом есть необходимость для встраивания в ваши решения. Но их функционал должен быть сохранен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e1XA3HMgxZR"
   },
   "source": [
    "# Файлы для работы с шаблонами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mf_G-APsIht"
   },
   "source": [
    "В разделе \"Алогритм\" показано что для чего нужно, так что имеет смысл сначала посетить его"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEDJQrK6gztR"
   },
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:08:48.656341Z",
     "iopub.status.busy": "2024-07-06T22:08:48.654681Z",
     "iopub.status.idle": "2024-07-06T22:08:48.676097Z",
     "shell.execute_reply": "2024-07-06T22:08:48.675027Z",
     "shell.execute_reply.started": "2024-07-06T22:08:48.656286Z"
    },
    "id": "UIktc3tpg3mZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "label2letter = {\n",
    "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\",\n",
    "    10: \"A\", 11: \"B\", 12: \"C\", 13: \"E\", 14: \"H\", 15: \"K\", 16: \"M\", 17: \"O\", 18: \"P\", 19: \"T\", 20: \"X\", 21: \"Y\"\n",
    "}\n",
    "\n",
    "class LettersPrediction(object):\n",
    "    def __init__(self):\n",
    "        self.model = resnet18()\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, out_features=22)\n",
    "        self.model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))\n",
    "        self.model.eval()\n",
    "\n",
    "        self.imgsz = 64\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((self.imgsz, self.imgsz)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def predict(self, img):\n",
    "        input_tensor = self.transform(img)\n",
    "        output_tensor = self.model(input_tensor.unsqueeze(0))\n",
    "        predicted = torch.argmax(output_tensor)\n",
    "        return label2letter[predicted.item()]\n",
    "\n",
    "    def predict_series(self, imgs):\n",
    "        s = \"\"\n",
    "        for img in imgs:\n",
    "            s += self.predict(img)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hg8KFqSTg_Rp"
   },
   "source": [
    "## template.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7y1aNYShssW7"
   },
   "source": [
    "Разбивает изображение на части по шаблонам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:08:51.035584Z",
     "iopub.status.busy": "2024-07-06T22:08:51.034027Z",
     "iopub.status.idle": "2024-07-06T22:08:51.063664Z",
     "shell.execute_reply": "2024-07-06T22:08:51.062549Z",
     "shell.execute_reply.started": "2024-07-06T22:08:51.035507Z"
    },
    "id": "Z4PxxUXZhDFI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "two_digit_region_template = [\n",
    "    {'pos': 1, 'p1': (0.067, 0.250), 'p2': (0.177, 0.92)},\n",
    "    {'pos': 2, 'p1': (0.19, 0.100), 'p2': (0.3, 0.92)},\n",
    "    {'pos': 3, 'p1': (0.3, 0.100), 'p2': (0.41, 0.92)},\n",
    "    {'pos': 4, 'p1': (0.41, 0.100), 'p2': (0.52, 0.92)},\n",
    "    {'pos': 5, 'p1': (0.53, 0.250), 'p2': (0.64, 0.92)},\n",
    "    {'pos': 6, 'p1': (0.64, 0.250), 'p2': (0.75, 0.92)},\n",
    "    {'pos': 7, 'p1': (0.77, 0.05), 'p2': (0.86, 0.7)},\n",
    "    {'pos': 8, 'p1': (0.86, 0.05), 'p2': (0.95, 0.7)}\n",
    "]\n",
    "\n",
    "three_digit_region_template = [\n",
    "    {'pos': 1, 'p1': (0.05, 0.250), 'p2': (0.16, 0.92)},\n",
    "    {'pos': 2, 'p1': (0.16, 0.100), 'p2': (0.27, 0.92)},\n",
    "    {'pos': 3, 'p1': (0.265, 0.100), 'p2': (0.375, 0.92)},\n",
    "    {'pos': 4, 'p1': (0.37, 0.100), 'p2': (0.48, 0.92)},\n",
    "    {'pos': 5, 'p1': (0.475, 0.250), 'p2': (0.585, 0.92)},\n",
    "    {'pos': 6, 'p1': (0.58, 0.250), 'p2': (0.69, 0.92)},\n",
    "    {'pos': 7, 'p1': (0.71, 0.05), 'p2': (0.795, 0.7)},\n",
    "    {'pos': 8, 'p1': (0.79, 0.05), 'p2': (0.875, 0.7)},\n",
    "    {'pos': 9, 'p1': (0.87, 0.05), 'p2': (0.96, 0.7)}\n",
    "]\n",
    "\n",
    "def apply_template(img, region_length):\n",
    "    if region_length == 2:\n",
    "        pattern = two_digit_region_template\n",
    "    elif region_length == 3:\n",
    "        pattern = three_digit_region_template\n",
    "    else:\n",
    "       raise ValueError(\"Неподдерживаемое разбиение на регионы. Поддерживаются только 2 и 3.\")\n",
    "\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    if H != 112 or W != 512:\n",
    "        raise ValueError(\"Форма изображения должна быть 512x112\")\n",
    "\n",
    "    crops = []\n",
    "    for pos in pattern:\n",
    "        sx, sy, ex, ey = *pos[\"p1\"], *pos[\"p2\"]\n",
    "        sx, sy, ex, ey = sx * W, sy * H, ex * W, ey * H\n",
    "        sx, sy, ex, ey = map(int, [sx, sy, ex, ey])\n",
    "        crops.append(img[sy : ey, sx : ex])\n",
    "\n",
    "    return crops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJGDPIfcjvlj"
   },
   "source": [
    "## Функция для деформации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REG1UQEqjlqM"
   },
   "source": [
    "Пропишите логику алгоритма по деформации внутри фунции img_deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:36:20.418263Z",
     "iopub.status.busy": "2024-07-06T22:36:20.416855Z",
     "iopub.status.idle": "2024-07-06T22:36:20.448636Z",
     "shell.execute_reply": "2024-07-06T22:36:20.447535Z",
     "shell.execute_reply.started": "2024-07-06T22:36:20.418209Z"
    },
    "id": "DpzXST6je3rj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def img_deformation(img):\n",
    "    # return img\n",
    "    def order_points(pts):\n",
    "        # Нахождение центра объекта\n",
    "        center = np.mean(pts)\n",
    "\n",
    "        # Перемещение систем координат в центр объекта\n",
    "        shifted = pts - center\n",
    "\n",
    "        # Нахождение углов, стянутых из центра в каждую угловую точку.\n",
    "        theta = np.arctan2(shifted[:, 0], shifted[:, 1])\n",
    "\n",
    "        # Возвращение вершин упорядоченных по Тете\n",
    "        ind = np.argsort(theta)\n",
    "        return pts[ind]\n",
    "    \n",
    "    def getContours(img, orig):\n",
    "        # Получение размеров изображения\n",
    "        height, width = img.shape[:2] \n",
    "        biggest = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.int32)  # Массив с размерами изображения\n",
    "        maxArea = 500\n",
    "\n",
    "        # Создание копии исходного изображения чтобы потом вернуть его\n",
    "        imgContour = orig.copy() \n",
    "        contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "\n",
    "        # Также указавыем индекс\n",
    "        index = -1\n",
    "        for i, cnt in enumerate(contours):\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 500:\n",
    "                peri = cv2.arcLength(cnt, True)\n",
    "                approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "                # print(approx)\n",
    "                if area > maxArea and len(approx) == 4:\n",
    "                    biggest = approx\n",
    "                    maxArea = area\n",
    "                    index = i  # Сохраняем индекс контура\n",
    "\n",
    "        if maxArea == 0:\n",
    "            maxArea = (width-1) * (height-1)\n",
    "\n",
    "        warped = None  \n",
    "        if index != None:\n",
    "            cv2.drawContours(imgContour, contours, index, (255, 0, 0), 3)\n",
    "\n",
    "            src = np.squeeze(biggest).astype(np.float32) # Source points\n",
    "\n",
    "            # Получаем корректный порядок точек\n",
    "            src = order_points(src)\n",
    "\n",
    "            # Вычисляем ширины и высоты нового изображения\n",
    "            widthA = np.linalg.norm(src[0] - src[1])\n",
    "            widthB = np.linalg.norm(src[2] - src[3])\n",
    "            maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "            heightA = np.linalg.norm(src[0] - src[3])\n",
    "            heightB = np.linalg.norm(src[1] - src[2])\n",
    "            maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "            # Определяем концевые точки\n",
    "            dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "            # Делаем преобразование перспективы\n",
    "            M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "            # Деформирруем изображение\n",
    "            warped = cv2.warpPerspective(orig, M, (maxWidth, maxHeight), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Optionally resize the warped image to a fixed size if needed\n",
    "            warped = cv2.resize(warped, (maxWidth, maxHeight))\n",
    "            warped = cv2.rotate(warped, cv2.ROTATE_90_CLOCKWISE)\n",
    "            warped = cv2.flip(warped, 1)\n",
    "\n",
    "\n",
    "        return biggest, imgContour, warped  # Change - also return drawn image\n",
    "\n",
    "    kernel = np.ones((3,3))\n",
    "    image = img\n",
    "\n",
    "    imgGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray,(5,5),1)\n",
    "    imgCanny = cv2.Canny(imgBlur,150,200)        \n",
    "    imgDial = cv2.dilate(imgCanny,kernel,iterations=2)\n",
    "    imgThres = cv2.erode(imgDial,kernel,iterations=2)\n",
    "    biggest, imgContour, warped = getContours(imgThres, image)  # Change\n",
    "\n",
    "    titles = ['Original', 'Blur', 'Canny', 'Dilate', 'Threshold', 'Contours', 'Warped'] \n",
    "    images = [image[...,::-1],  imgBlur, imgCanny, imgDial, imgThres, imgContour, warped]\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFVZ3lDFg7G5"
   },
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqXxfzqcsh00"
   },
   "source": [
    "Выполняет предсказание для изображений разбитых по 2 и 3 шаблону"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-06T22:36:25.688433Z",
     "iopub.status.busy": "2024-07-06T22:36:25.687271Z",
     "iopub.status.idle": "2024-07-06T22:38:55.117774Z",
     "shell.execute_reply": "2024-07-06T22:38:55.116647Z",
     "shell.execute_reply.started": "2024-07-06T22:36:25.688385Z"
    },
    "id": "LifbKv1fg9Mx",
    "outputId": "46137632-334e-465b-b519-7ad9e2eec2fa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029it [02:29,  6.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "#from template import apply_template\n",
    "#from model import LettersPrediction\n",
    "\n",
    "data_path = Path(DATASET_PATH)\n",
    "\n",
    "\n",
    "regions_type = [2, 3]\n",
    "model = LettersPrediction()\n",
    "\n",
    "\n",
    "result = []\n",
    "for p in tqdm(data_path.iterdir()):\n",
    "\n",
    "    if not p.suffix in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "        continue\n",
    "    result.append(\n",
    "        {\n",
    "            \"image_name\": p.stem,\n",
    "            \"prediction_region_length_2\": \"\",\n",
    "            \"prediction_region_length_3\": \"\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    img = cv2.imread(str(p))\n",
    "\n",
    "    #вызов фунции деформации\n",
    "    img = img_deformation(img)\n",
    "    ########################\n",
    "\n",
    "    img = cv2.resize(img, (512,112))\n",
    "\n",
    "    for region_type in regions_type:\n",
    "\n",
    "        crops = apply_template(img, region_type)\n",
    "\n",
    "        lp_number = model.predict_series(crops)\n",
    "        result[-1][f\"prediction_region_length_{region_type}\"] = lp_number\n",
    "\n",
    "pd.DataFrame(result).to_csv('modelPredict.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:39:37.858457Z",
     "iopub.status.busy": "2024-07-06T22:39:37.856953Z",
     "iopub.status.idle": "2024-07-06T22:39:39.091655Z",
     "shell.execute_reply": "2024-07-06T22:39:39.090363Z",
     "shell.execute_reply.started": "2024-07-06T22:39:37.858411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "correspondance = pd.read_csv('./correspondance.csv')\n",
    "modelPredict = pd.read_csv('./modelPredict.csv')\n",
    "sums = 0\n",
    "for i in range(len(correspondance)):\n",
    "    im_name = correspondance.iloc[i]['image_name']\n",
    "    num = correspondance.iloc[i]['number']\n",
    "    \n",
    "    flag_2 = modelPredict[modelPredict['image_name'] == im_name]['prediction_region_length_2'].values[0]\n",
    "    flag_3 = modelPredict[modelPredict['image_name'] == im_name]['prediction_region_length_3'].values[0]\n",
    "    \n",
    "    if num==flag_2 or num==flag_3:\n",
    "        sums+=1\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyZqFjLqhFDx"
   },
   "source": [
    "# Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhmRgmf8wbpY"
   },
   "source": [
    "![](https://sun9-2.userapi.com/impg/SfgCnkIYJeC_4clAh69dvC6ZwmBT9dLmMkh25A/DvScgey4ZCg.jpg?size=1916x1079&quality=96&sign=2ef5e9fadc1d8635c4963fb99affd07d&type=album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T21:17:41.256155Z",
     "iopub.status.busy": "2024-07-06T21:17:41.254505Z",
     "iopub.status.idle": "2024-07-06T21:17:41.280600Z",
     "shell.execute_reply": "2024-07-06T21:17:41.279521Z",
     "shell.execute_reply.started": "2024-07-06T21:17:41.256084Z"
    },
    "id": "9QTndEKnnMcN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#Рисует на изображение template\n",
    "def draw_regions(img, region_length):\n",
    "    if region_length == 2:\n",
    "        pattern = two_digit_region_template\n",
    "    elif region_length == 3:\n",
    "        pattern = three_digit_region_template\n",
    "    else:\n",
    "        raise ValueError(\"Неподдерживаемое разбиение на регионы. Поддерживаются только 2 и 3.\")\n",
    "\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    if H != 112 or W != 512:\n",
    "        raise ValueError(\"Форма изображения должна быть 512x112\")\n",
    "\n",
    "    for pos in pattern:\n",
    "        sx, sy, ex, ey = *pos[\"p1\"], *pos[\"p2\"]\n",
    "        sx, sy, ex, ey = int(sx * W), int(sy * H), int(ex * W), int(ey * H)\n",
    "        cv2.rectangle(img, (sx, sy), (ex, ey), (0, 255, 0), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "#Визуализирует изображения из датасета\n",
    "def draw(folder_path, show_template=False, template=2):\n",
    "\n",
    "    file_list = os.listdir(folder_path)\n",
    "    image_files = [f for f in file_list if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "    # Устанавливаем количество изображений на строку\n",
    "    images_per_row = 5\n",
    "\n",
    "    num_rows = len(image_files) // images_per_row + int(len(image_files) % images_per_row != 0)\n",
    "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(15, 3 * num_rows))\n",
    "\n",
    "    for i in range(num_rows * images_per_row):\n",
    "        if i < len(image_files):\n",
    "            ax = axes.flat[i]\n",
    "            img_path = os.path.join(folder_path, image_files[i])\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if show_template:\n",
    "              img = img_deformation(img)\n",
    "              img = cv2.resize(img, (512,112))\n",
    "              img_with_rectangles = draw_regions(img, template)\n",
    "\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(os.path.basename(img_path))\n",
    "        else:\n",
    "            axes.flat[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flsib02ls9ir"
   },
   "source": [
    "Визуализируем изображения из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 978
    },
    "execution": {
     "iopub.execute_input": "2024-07-06T21:24:00.651423Z",
     "iopub.status.busy": "2024-07-06T21:24:00.650208Z",
     "iopub.status.idle": "2024-07-06T21:24:00.687995Z",
     "shell.execute_reply": "2024-07-06T21:24:00.686554Z",
     "shell.execute_reply.started": "2024-07-06T21:24:00.651372Z"
    },
    "id": "Lps3eNRnnOWN",
    "outputId": "5e7b1d3b-320f-41e1-b38f-c5ac2b0d8ba5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw(DATASET_PATH, show_template=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6vYWqjBpmft"
   },
   "source": [
    "Теперь визуализируем шаблон 2 для каждого изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "execution": {
     "iopub.execute_input": "2024-07-06T21:23:56.930762Z",
     "iopub.status.busy": "2024-07-06T21:23:56.929424Z",
     "iopub.status.idle": "2024-07-06T21:23:56.963640Z",
     "shell.execute_reply": "2024-07-06T21:23:56.962591Z",
     "shell.execute_reply.started": "2024-07-06T21:23:56.930711Z"
    },
    "id": "jbqwWwG7pyqc",
    "outputId": "e43c1205-1821-4cf1-b931-434314f37ffa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw(DATASET_PATH_MINI, show_template=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UO3CBiOaqQkz"
   },
   "source": [
    "Теперь визуализируем шаблон 3 для каждого изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "execution": {
     "iopub.execute_input": "2024-07-06T21:24:03.771656Z",
     "iopub.status.busy": "2024-07-06T21:24:03.770448Z",
     "iopub.status.idle": "2024-07-06T21:24:03.791362Z",
     "shell.execute_reply": "2024-07-06T21:24:03.790294Z",
     "shell.execute_reply.started": "2024-07-06T21:24:03.771620Z"
    },
    "id": "8ZfF_GN-qIxL",
    "outputId": "3bdfddd9-6e92-4aec-df56-60d6e12f8678",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw(DATASET_PATH, show_template=True, template = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7-RHZY7qb0i"
   },
   "source": [
    "# Вывод модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:33:20.319790Z",
     "iopub.status.busy": "2024-07-06T22:33:20.318570Z",
     "iopub.status.idle": "2024-07-06T22:33:20.340840Z",
     "shell.execute_reply": "2024-07-06T22:33:20.339698Z",
     "shell.execute_reply.started": "2024-07-06T22:33:20.319739Z"
    },
    "id": "nvjlg879qdmj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./modelPredict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q5QyX9PxSx4"
   },
   "source": [
    "Модель делает предсказание разбивая изображение и по шаблону 2 и по шаблону 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "execution": {
     "iopub.execute_input": "2024-07-06T22:33:24.088371Z",
     "iopub.status.busy": "2024-07-06T22:33:24.087149Z",
     "iopub.status.idle": "2024-07-06T22:33:24.116850Z",
     "shell.execute_reply": "2024-07-06T22:33:24.115723Z",
     "shell.execute_reply.started": "2024-07-06T22:33:24.088335Z"
    },
    "id": "ct2T5-UZr-yW",
    "outputId": "d3e24de9-6c12-431b-b8d1-18844878a3ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>prediction_region_length_2</th>\n",
       "      <th>prediction_region_length_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0a6aa844e3834971</td>\n",
       "      <td>YCY43Y5O</td>\n",
       "      <td>Y235KP75O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ac22544b27be4ef</td>\n",
       "      <td>C355O4T9</td>\n",
       "      <td>413542CT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0b5e5490607902fe</td>\n",
       "      <td>41EEEECE</td>\n",
       "      <td>H1B4EE333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a8438252d687e6e</td>\n",
       "      <td>P489KT16</td>\n",
       "      <td>P43MM11H6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0b59a6532708ac55</td>\n",
       "      <td>M2O2XT44</td>\n",
       "      <td>Y2O221T44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>fed01b5793ae24dc</td>\n",
       "      <td>M61444T3</td>\n",
       "      <td>M614HOT73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>ffdab76d3e777688</td>\n",
       "      <td>B31TMTY2</td>\n",
       "      <td>B0YTBX8P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>00c980fd3135c4af</td>\n",
       "      <td>48E1CH60</td>\n",
       "      <td>E817KTHYO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>ff670e356ab0fee5</td>\n",
       "      <td>C65OT15O</td>\n",
       "      <td>Y45OPPTYO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>ff84142ca87fed63</td>\n",
       "      <td>0P116497</td>\n",
       "      <td>0012HO777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1029 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_name prediction_region_length_2 prediction_region_length_3\n",
       "0     0a6aa844e3834971                   YCY43Y5O                  Y235KP75O\n",
       "1     0ac22544b27be4ef                   C355O4T9                  413542CT2\n",
       "2     0b5e5490607902fe                   41EEEECE                  H1B4EE333\n",
       "3     0a8438252d687e6e                   P489KT16                  P43MM11H6\n",
       "4     0b59a6532708ac55                   M2O2XT44                  Y2O221T44\n",
       "...                ...                        ...                        ...\n",
       "1024  fed01b5793ae24dc                   M61444T3                  M614HOT73\n",
       "1025  ffdab76d3e777688                   B31TMTY2                  B0YTBX8P1\n",
       "1026  00c980fd3135c4af                   48E1CH60                  E817KTHYO\n",
       "1027  ff670e356ab0fee5                   C65OT15O                  Y45OPPTYO\n",
       "1028  ff84142ca87fed63                   0P116497                  0012HO777\n",
       "\n",
       "[1029 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
